submit()
boring_function(_function("Minha primeira função!"))
boring_function("Minha primeira função!")
boring_function
submit()
my_mean(c(4,5,10))
submit()
remainder(5)
remainder(11,5)
remainder(divisor=11, num=5)
remainder(4, div=2)
args(remainder)
submit()
evaluate(c(1.4,3.6,7.9.8.8))
evaluate(c(1.4,3.6,7.9,8.8))
evaluate(sum, c(1.4,3.6,7.9,8.8))
evaluate(sd, c(1.4,3.6,7.9,8.8))
evaluate(function(x {x + 1}, 6))
evaluate(function(x) {x + 1}, 6)
evaluate(function(x) { x[1]}, c(8,4,0))
evaluate(function(x) { x[length(x)]}, c(8,4,0))
?paste
paste("Programar", "é", "divertido!")
submit()
telegram("teste")
submit()
mad_libs(place="TESTE", adjective="TTEESSTTEE", noun="TTTTTHHTTHTHT")
submit()
"EU" %p% "adoro" %p% "R!"
"Eu" %p% "adoro" %p% "R!"
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
sim(mydf)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, coutry:r_arch)
select(cran, country:r_arch)
cran
select(cran, -time())
select(cran, -time
)
-5:20
-(5:20)
select(cran, -(x:size))
select(cran, -(X:size))
filter(cran, package== "swirl")
filter(cran, r_version == "3.1.1", country== "US")
filter(cran, C(r_version, "3.1.1"))
filter(cran, Comparison(r_version, "3.1.1"))
filter(cran)
?Comparison
filter(cran, r_version <= "3.0.2", country== "IN")
filter(cran, r_version <= "3.0.2", country== "IN" | country == "US")
filter(cran, country== "IN" | country == "US")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3,5, NA, 10))
!is.na(c(3,5, NA, 10))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size, ip_id)
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, packge, ip_id)
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran2=3
cran3
mutate(cran3, size_mb= size / 2 ^ 20)
mutate(cran3, size_gb= size_mb / 2 ^ 20)
mutate(cran3, size_mb= size / 2 ^ 20, size_gb = size_mb / 2 ^ 10)
mutate(cran3, correct_size= size - 1000)
mutate(cran3, correct_size= size + 1000)
summarize(cran, avg_bytes(mean(size)))
summarize(cran, avg_bytes= mean(size))
install.packages("swirl")
library(swirl)
select_language(language = 'portuguese')
library(swirl)
uninstall_course('Aprenda_R_no_R')
install_course_github('elthonf','Aprenda_R_no_R')
swirl
swirl()
data(cars)
?cars
head(cars)
plot(cars)
?plot
plot(x = cars$dist, y = cars$speed)
plot(x = cars$speed, y = cars$dist)
plot(x = cars$dist, y = cars$speed)
?plot
plot(x = cars$speed, y = cars$dist, xlab = 'Velocidade')
plot(x = cars$speed, y = cars$dist, xlab = 'Velocidade', ylab = 'Distancia de parada')
plot(x = cars$speed, y = cars$dist, ylab = 'Distancia de parada')
plot(x = cars$speed, y = cars$dist, xlab = 'Velocidade', ylab = 'Distancia de parada')
plot(cars, main="Meu Plot")
?plot
plot(cars, sub="Meu subtitulo")
plot(cars, col=2)
plot(cars, xlim=c(10,15))
plot(cars, pch=2)
data(mtcars)
head(mtacars)
head(mtcars)
?boxplot
boxplot(data=mtcars, formula=mpg ^cyl)
boxplot(data=mtcars, formula=mpg~cyl)
boxplot(mtcars, formula=mpg~cyl)
boxplot(formula=mpg~cyl, data=mtcars)
hist(mtcars$mpg)
cmat
plot(cx, cy, paste(cols1), pch=3, cex=2, lwd=2)
plot(cx, cy)
plot(cx, cy, col=ols1, pch=3, cex=2, lwd=2)
plot(cx, cy, col=cols1, pch=3, cex=2, lwd=2)
plot(cx, cy, col=c("red", "orange", "purple"), pch=3, cex=2, lwd=2)
points(cx, cy, col=c("red", "orange", "purple"), pch=3, cex=2, lwd=2)
mdist(x,y,cx,cy)
distTmp <- mdist(x,y,cx,cy)
distTmp
combine(a)
c <- 3
c(3)
c(c)
c(c=c)
c <- function(c){ cbind(c)}
c(c)
c(1)
rm(c)
c <- function(c) { return(c)}
c(1)
c(1,2)
c(1)
c(1:9)
c(c=
1)
1
sessionInfo()
install.packages("ggplot2")
library(ggplot2)
getwd()
qplot()
install.packages("Amelia")
install.packages("caret")
install.packages("ggplot2")
install.packages("dplyr")
install.packages("reshape")
install.packages("randomForest")
install.packages("e1071")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
library(Amelia)
library(ggplot2)
library(caret)
library(reshape)
library(randomForest)
library(dplyr)
library(e1071)
# Carregando os datasets
dataset <- read.csv("credit-card.csv")
# Idade
head(dataset$AGE)
dataset$AGE <- cut(dataset$AGE, c(0,30,50,100), labels = c("Jovem","Adulto","Idoso"))
head(dataset$AGE)
# Sexo
dataset$SEX <- cut(dataset$SEX, c(0,1,2), labels = c("Masculino","Feminino"))
head(dataset$SEX)
# Escolaridade
dataset$EDUCATION <- cut(dataset$EDUCATION, c(0,1,2,3,4),
labels = c("Pos Graduado","Graduado","Ensino Medio","Outros"))
head(dataset$EDUCATION)
# Estado Civil
dataset$MARRIAGE <- cut(dataset$MARRIAGE, c(-1,0,1,2,3),
labels = c("Desconhecido","Casado","Solteiro","Outros"))
head(dataset$MARRIAGE)
# Convertendo a variavel que indica pagamentos para o tipo fator
dataset$PAY_0 <-as.factor(dataset$PAY_0)
dataset$PAY_2 <-as.factor(dataset$PAY_2)
dataset$PAY_3 <-as.factor(dataset$PAY_3)
dataset$PAY_4 <-as.factor(dataset$PAY_4)
dataset$PAY_5 <-as.factor(dataset$PAY_5)
dataset$PAY_6 <-as.factor(dataset$PAY_6)
# Alterando a variavel dependente para o tipo fator
dataset$default.payment.next.month <- as.factor(dataset$default.payment.next.month)
head(dataset)
str(dataset)
# Renomeando a coluna de classe
colnames(dataset)
colnames(dataset)[25] <- "inadimplente"
colnames(dataset)
# Verificando valores missing e removendo do dataset
sapply(dataset, function(x) sum(is.na(x)))
missmap(dataset, main = "Valores Missing Observados")
dataset <- na.omit(dataset)
# Removendo a primeira coluna ID
dataset$ID <- NULL
View(dataset)
# Total de inadimplentes versus nao-inadimplentes
table(dataset$inadimplente)
# Plot da distribuicao usando ggplot
qplot(inadimplente, data = dataset, geom = "bar") + theme(axis.text.x = element_text(angle = 90, hjust = 1))
# Set the seed
set.seed(12345)
TrainingDataIndex <- createDataPartition(dataset$inadimplente, p = 0.45, list = FALSE)
TrainingDataIndex
# Criar Dados de Treinamento como subconjunto do conjunto de dados com numeros de indice de linha
# conforme identificado acima e todas as colunas
trainData <- dataset[TrainingDataIndex,]
table(trainData$inadimplente)
# Veja porcentagens entre as classes
prop.table(table(trainData$inadimplente))
# Numero de linhas no dataset de treinamento
nrow(trainData)
# Compara as porcentagens entre as classes de treinamento e dados originais
DistributionCompare <- cbind(prop.table(table(trainData$inadimplente)), prop.table(table(dataset$inadimplente)))
colnames(DistributionCompare) <- c("Treinamento", "Original")
DistributionCompare
# Melt Data - Converte colunas em linhas
meltedDComp <- melt(DistributionCompare)
meltedDComp
# Plot para ver a distribuicao do treinamento vs original - eh representativo ou existe sobre / sob amostragem?
ggplot(meltedDComp, aes(x = X1, y = value)) + geom_bar( aes(fill = X2), stat = "identity", position = "dodge") + theme(axis.text.x = element_text(angle = 90, hjust = 1))
# Tudo o que nao esta no dataset de treinamento esta no dataset de teste. Observe o sinal - (menos)
testData <- dataset[-TrainingDataIndex,]
# Usaremos uma validacao cruzada de 10 folds para treinar e avaliar modelo
TrainingParameters <- trainControl(method = "cv", number = 10)
# Construindo o Modelo
rf_model <- randomForest(inadimplente ~ ., data = trainData)
rf_model
# Conferindo o erro do modelo
plot(rf_model, ylim = c(0,0.36))
legend('topright', colnames(rf_model$err.rate), col = 1:3, fill = 1:3)
# importancia das variaveis preditoras para as previsoes
varImpPlot(rf_model)
# importancia das variaveis preditoras para as previsoes
varImpPlot(rf_model)
# Obtendo as variaveis mais importantes
importance    <- importance(rf_model)
varImportance <- data.frame(Variables = row.names(importance), Importance = round(importance[ ,'MeanDecreaseGini'],2))
rankImportance <- varImportance %>%
mutate(Rank = paste0('#', dense_rank(desc(Importance))))
# Usando ggplot2 para visualizar a importancia relativa das variaveis
ggplot(rankImportance, aes(x = reorder(Variables, Importance), y = Importance, fill = Importance)) +
geom_bar(stat='identity') +
geom_text(aes(x = Variables, y = 0.5, label = Rank), hjust=0, vjust=0.55, size = 4, colour = 'red') +
labs(x = 'Variables') +
coord_flip()
# Previsoes
predictionrf <- predict(rf_model, testData)
# Confusion Matrix
cmrf <- confusionMatrix(predictionrf, testData$inadimplente, positive = "1")
cmrf
?randomForest
library()
library(swirl)
swirl()
data(cars)
?cars
head(cars)
plot(cars)
?plot
plot(data=cars, x=speed, y=dist)
plot(x=cars$speed, y=cars$dist)
plot(x=cars$dist, y=cars$speed)
plot(x=cars$speed, y=cars$dist)
plot(x=cars$speed, y=cars$dist, xlab="Velocidade")
plot(x=cars$speed, y=cars$dist, xlab="Velocidade", ylab="Distânvia de parada")
plot(x=cars$speed, y=cars$dist, xlab="Velocidade", ylab="Distância de parada")
plot(x=cars$speed, y=cars$dist, ylab="Distância de parada")
plot(x=cars$speed, y=cars$dist, ylab="Distancia de parada")
plot(x=cars$speed, y=cars$dist, xlab="Velocidade", ylab="Distancia de parada")
plot(x=cars$speed, y=cars$dist, xlab="Velocidade", main="Meu plot")
plot(cars, xlab="Velocidade", main="Meu plot")
plot(cars, main="Meu plot")
plot(cars, main="Meu Plot")
?plot(cars, main="Meu Plot", )
plot(cars, main="Meu Plot", sub="Meu subtitulo")
plot(cars, sub="Meu subtitulo")
plot(cars, col=2)
plot(cars, xlim=c(10,15))
plot(cars, sub="Meu subtitulo")
plot(cars, pch=2)
data("mtcars")
data(mtcars)
?boxplot
boxplot(data=mtcars, mpg^cyl)
boxplot(data=mtcars, mpg~cyl)
boxplot(data=mtcars, formula=mpg~cyl)
boxplot(formula=mpg~cyl, data=mtcars )
?hist
hist(mtcars$mpg)
install.packages("devtools")
devtools::install_github("IRkernel/IRkernel")
IRkernel::installspec()
IRkernel::installspec()
IRkernel::installspec(user=FALSE)
IRkernel::installspec(user=FALSE)
IRkernel::installspec(name = 'ir32', displayname = 'R 3.2')
IRkernel::installspec(name = 'ir33', displayname = 'R 3.3')
IRkernel::installspec(name = 'ir32', displayname = 'R 3.2')
IRkernel::installspec()
install.packages('IRkernel')
install.packages("IRkernel")
IRkernel::installspec()
install.packages(c('crayon', 'pbdZMQ', 'devtools'))
devtools::install_github(paste0('IRkernel/', c('repr', 'IRdisplay', 'IRkernel')))
install.packages(c("crayon", "pbdZMQ", "devtools"))
install.packages(c("crayon", "pbdZMQ", "devtools"))
install.packages(c("crayon", "pbdZMQ", "devtools"))
devtools::install_github(paste0('IRkernel/', c('repr', 'IRdisplay', 'IRkernel')))
IRkernel::installspec()
system2("jupyter", c("kernelspec", "--version"), FALSE, FALSE)
system2("conda", c("--version"), FALSE, FALSE)
setwd("C:/Projetos/Importing-Cleaning-Data-in-R/")
#Dealing with outliers and obvious errors
students3 <- read.csv("DataSets/students_with_dates.csv")
summary(students3)
library(dplyr)
library(readr)
weather <- read_rds("DataSets/weather.rds")
# Verify that weather is a data.frame
class(weather)
# Check the dimensions
dim(weather)
# View the column names
names(weather)
# View the structure of the data
str(weather)
# Load dplyr package
library(dplyr)
# Look at the structure using dplyr's glimpse()
glimpse(weather)
# View a summary of the data
summary(weather)
# View first 6 rows
head(weather)
# View first 15 rows
head(weather, 15)
# View the last 6 rows
tail(weather)
# View the last 10 rows
tail(weather,10)
# Load the tidyr package
library(tidyr)
# Gather the columns
weather2 <- gather(weather, day, value, X1:X31, na.rm = TRUE)
# View the head
head(weather2)
# First remove column of row names
without_x <- weather2[, -1]
# Spread the data
weather3 <- spread(without_x, measure, value)
# View the head
head(weather3)
# Load the stringr and lubridate packages
library(stringr)
library(lubridate)
# Remove X's from day column
weather3$day <- str_replace(weather3$day, "X", "")
# Unite the year, month, and day columns
weather4 <- unite(weather3, date, year, month, day, sep = "-")
# Convert date column to proper date format using lubridates's ymd()
weather4$date <- ymd(weather4$date)
# Rearrange columns using dplyr's select()
weather5 <- select(weather4, date, Events, CloudCover:WindDirDegrees)
# View the head of weather5
head(weather5)
# View the structure of weather5
str(weather5)
# Examine the first 20 rows of weather5. Are most of the characters numeric?
head(weather5, 20)
# See what happens if we try to convert PrecipitationIn to numeric
as.numeric(weather5$PrecipitationIn)
# Count missing values
sum(is.na(weather6))
# Find missing values
summary(weather6)
# Find indices of NAs in Max.Gust.SpeedMPH
ind <- which(is.na(weather6$Max.Gust.SpeedMPH))
# Look at the full rows for records missing Max.Gust.SpeedMPH
weather6[ind, ]
# Examine the first 20 rows of weather5. Are most of the characters numeric?
head(weather5, 20)
# See what happens if we try to convert PrecipitationIn to numeric
as.numeric(weather5$PrecipitationIn)
# Replace "T" with "0" (T = trace)
weather5$PrecipitationIn <- str_replace(weather5$PrecipitationIn, "T", "0")
# Convert characters to numerics
weather6 <- mutate_at(weather5, vars(CloudCover:WindDirDegrees), funs(as.numeric))
# Look at result
str(weather6)
# Count missing values
sum(is.na(weather6))
# Find missing values
summary(weather6)
# Find indices of NAs in Max.Gust.SpeedMPH
ind <- which(is.na(weather6$Max.Gust.SpeedMPH))
# Look at the full rows for records missing Max.Gust.SpeedMPH
weather6[ind, ]
# Review distributions for all variables
summary(weather6)
# Find row with Max.Humidity of 1000
ind <- which(weather6$Max.Humidity == 1000)
# Look at the data for that day
weather6[ind, ]
# Change 1000 to 100
weather6$Max.Humidity[ind] <- 100
# Look at summary of Mean.VisibilityMiles
summary(weather6$Mean.VisibilityMiles)
# Get index of row with -1 value
ind <- which(weather6$Mean.VisibilityMiles == -1)
# Look at full row
weather6[ind, ]
# Set Mean.VisibilityMiles to the appropriate value
weather6$Mean.VisibilityMiles[ind] <- 10
# Look at histogram for MeanDew.PointF
hist(weather6$MeanDew.PointF)
# Look at histogram for Min.TemperatureF
hist(weather6$Min.TemperatureF)
# Compare to histogram for Mean.TemperatureF
hist(weather6$Mean.TemperatureF)
source('C:/Projetos/Importing-Cleaning-Data-in-R/Cleaning Data in R.R', echo=TRUE)
# Replace empty cells in events column
weather6$events[weather6$events == ""] <- "None"
# Print the first 6 rows of weather6
head(weather6)
sales <- read.csv("DataSets/sales.csv", stringsAsFactors = FALSE)
# View dimensions of sales
dim(sales)
# Inspect first 6 rows of sales
head(sales)
# View column names of sales
names(sales)
# Look at structure of sales
str(sales)
# View a summary of sales
summary(sales)
# Load dplyr
library(dplyr)
# Get a glimpse of sales
glimpse(sales)
# Define a vector of column indices: keep
keep <- 5:(ncol(sales2) - 15)
# Subset sales2 using keep: sales3
sales3 <- sales2[,keep]
# Remove the first column of sales: sales2
sales2 <- sales[,-1]
# Define a vector of column indices: keep
keep <- 5:(ncol(sales2) - 15)
# Subset sales2 using keep: sales3
sales3 <- sales2[,keep]
# Load tidyr
library(tidyr)
# Split event_date_time: sales4
sales4 <- separate(sales3, event_date_time,
c("event_dt", "event_time"), sep = " ")
# Split sales_ord_create_dttm: sales5
sales5 <- separate(sales4, sales_ord_create_dttm,
c("ord_create_dt", "ord_create_time"), sep = " ")
# Define an issues vector
issues <- c( 2516, 3863, 4082, 4183)
# Print values of sales_ord_create_dttm at these indices
sales3[issues, ]$sales_ord_create_dttm
# Print a well-behaved value of sales_ord_create_dttm
sales3[2517, ]$sales_ord_create_dttm
# Load stringr
library(stringr)
# Find columns of sales5 containing "dt": date_cols
date_cols <- str_detect(names(sales5), "dt")
# Load lubridate
library(lubridate)
# Coerce date columns into Date objects
sales5[, date_cols] <- lapply(sales5[, date_cols], ymd)
# Load stringr
library(stringr)
# Find columns of sales5 containing "dt": date_cols
date_cols <- str_detect(names(sales5), "dt")
# Load lubridate
install.packages("lubridate")
library(lubridate)
# Coerce date columns into Date objects
sales5[, date_cols] <- lapply(sales5[, date_cols], ymd)
library(lubridate)
# Load lubridate
install.packages("lubridate")
library(lubridate)
library(lubridate)
library(lubridate)
require(lubridate)
# Coerce date columns into Date objects
sales5[, date_cols] <- lapply(sales5[, date_cols], ymd)
